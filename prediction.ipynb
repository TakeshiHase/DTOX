{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cda66445",
   "metadata": {},
   "source": [
    "The following code load optimized deep convoluational neural network model for angle 1 ('resnet18.pth') and predict classes for sample 3D-surface images in a directory for the samples ('./sample_data/'). 'prediction_results.txt' includes prediction results for each 3D-surface images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8422e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch import optim\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageOps\n",
    "import os\n",
    "import matplotlib as plt\n",
    "import glob\n",
    "import re\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b95d35ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thase\\anaconda3_2023\\Lib\\site-packages\\torch\\serialization.py:995: UserWarning: 'torch.load' received a zip file that looks like a TorchScript archive dispatching to 'torch.jit.load' (call 'torch.jit.load' directly to silence this warning)\n",
      "  warnings.warn(\"'torch.load' received a zip file that looks like a TorchScript archive\"\n"
     ]
    }
   ],
   "source": [
    "#image size setting\n",
    "image_size = 224\n",
    "\n",
    "#load the trained model\n",
    "model_from_all = torch.load('resnet18.pth', map_location=\"cpu\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#check if the model is in inference mode. False indicates that the model is in inference mode.\n",
    "print(model_from_all.training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63537c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list for index and prediction\n",
    "index_list = []\n",
    "prediction_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2529b6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./sample_data\\\\1423060_at_ML0-TCV_TTG037-L.JPG', './sample_data\\\\1434367_s_at_ML0-TCV_TTG118-L.JPG', './sample_data\\\\1439675_at_ML0-TCV_TTG129-L.JPG', './sample_data\\\\1460196_at_ML0-TCV_TTG131B-L.JPG', './sample_data\\\\1460258_at_ML0-TCV_TTG131B-L.JPG', './sample_data\\\\1460425_at_ML0-TCV_TTG131B-L.JPG']\n"
     ]
    }
   ],
   "source": [
    "#list up input image files wthinin a directory (in this case, ./sample_data/). \n",
    "ddir = './sample_data/*.JPG'\n",
    "l = glob.glob(ddir)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0e1de23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction\n",
    "for i in l:\n",
    "   img = Image.open(i)\n",
    "   trans = transforms.Compose([\n",
    "           transforms.Resize(image_size),\n",
    "           transforms.ToTensor(),\n",
    "       ])\n",
    "   img = trans(img).unsqueeze(0)\n",
    "   output = model_from_all(img.to(device))\n",
    "   _, prediction = torch.max(output, 1)\n",
    "   index_list.append(i)\n",
    "   if prediction.cpu().numpy()[0] == 0:\n",
    "      prediction_list.append('DOWN')\n",
    "   elif prediction.cpu().numpy()[0] == 1:\n",
    "      prediction_list.append('NS')\n",
    "   elif prediction.cpu().numpy()[0] == 2:\n",
    "      prediction_list.append('UP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f5e33d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         file_name prediction\n",
      "0    ./sample_data\\1423060_at_ML0-TCV_TTG037-L.JPG         UP\n",
      "1  ./sample_data\\1434367_s_at_ML0-TCV_TTG118-L.JPG         UP\n",
      "2    ./sample_data\\1439675_at_ML0-TCV_TTG129-L.JPG         UP\n",
      "3   ./sample_data\\1460196_at_ML0-TCV_TTG131B-L.JPG         UP\n",
      "4   ./sample_data\\1460258_at_ML0-TCV_TTG131B-L.JPG         UP\n",
      "5   ./sample_data\\1460425_at_ML0-TCV_TTG131B-L.JPG         UP\n"
     ]
    }
   ],
   "source": [
    "#output prediction results\n",
    "report = pd.DataFrame()\n",
    "report['file_name'] = index_list\n",
    "report['prediction'] = prediction_list\n",
    "report.to_csv(\"prediction_results.txt\",sep=\"\\t\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccaf0e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
